\begin{savequote}[0.55\linewidth]
	\begin{fancyquote}
		Measure twice and cut once.
	\end{fancyquote}
	\qauthor{Carpentry rule of thumb}

	\begin{fancyquote}
		But cut\hspace{1em}ting is more fun than m\hspace{0.5em}\raisebox{-0.1em}{eas}\hspace{0.5em}\raisebox{-0.3em}{uri}\hspace{0.5em}\raisebox{-0.5em}{ng!}
	\end{fancyquote}
	\qauthor{Anonymous}
\end{savequote}

\chapter{Planning and Analysis}\label{ch:analysis}
% 2. Planning and Analysis
%    [ Analysis of project requirements. How is the older codebase
%      structured. How is refactoring accomplished. ]

Before writing a single line of code, it is a good practice to understand the
scope of the problem. Gathering the deliverables and requirements of the
project is necessary not only for understanding how long the project will take,
but also the order in which to implement each component. Establishing this
order proves very useful for later in the testing phase of the project
(Chapter~\ref{ch:testing}).

\section{System objectives}\label{sec:objectives}

As opposed to the scientific deliverables discussed in
Section~\ref{sec:motivation}, the system objectives are the engineering
deliverables; these are more closely tied to the Design and Implementation
phases as these objectives influence decisions made about the underlying
resources and system architecture.

% Define the project objectives (engineering deliverables).
% These are expanded from the list given in the abstract.
The \emph{first objective} is a complete conversion of the
existing code from MATLAB to native code which will be referred to
as \gls{orionmat} and \gls{orionc} respectively. This involves an
analysis of the existing code to see which parts of the algorithm will be converted.

The \emph{second objective} is the ability to easily integrate the system with
Vaa3D as a plugin. This requires looking at the interface that
Vaa3D uses and creating compatible data structures so that the
data does not need to converted between multiple formats in
memory.

The \emph{third objective} is a test suite to verify that the
components of the \gls{orionc} system operate on the same input
and produce expected outputs which are comparable to the
\gls{orionmat} code and follow expected properties outlined in the
design.

The \emph{fourth objective} is to ensure that the system provides
a means for reproducibility by testing the software under different
conditions and making it possible to the replicate the software
environment so that others may run the software.

\section{Benefits}
% Analyse project requirements: why are these objectives
% beneficial?

The first objective requires that all of the MATLAB code be
replaced by native code. This provides several benefits:
\begin{enumerate}[label={\alph*)}]
	\item it removes a dependency on MATLAB which requires that
		all users either install a licensed copy of MATLAB
		or use the MATLAB Compiler Runtime for deployment;
	\item it provides the benefit that changes in
		function behaviour between versions of
		MATLAB do not effect the output of the
		code; and
	\item certain operations can run faster in native code than
		in MATLAB.
\end{enumerate}

The second objective will allow the code to work with a widely used
tool for visualisation and analysis. Furthermore, integrating with
one tool will provide a framework for integrating with other tools
such as ImageJ~\autocite{Schneider2012}.

The third objective provides a safety net so that current and
future development clearly defines the expectation of the code
not only in the documentation, but as executable tests that can be
used to indicate when a change causes these expectations to no
longer be met.

The fourth objective is what ensues that the previously discussed
benefits are available for others to use on their machines and
allowing for reproducibility of the neuron reconstruction results.
This objective is what makes the project an ``open-science''
project.

\section{Design principles}
% Define technical principles that relate to project objectives

In order to meet the objectives listed in Section~\ref{sec:objectives},
certain principles need to be agreed upon before the design phase
can begin. These principles are meant to direct how resources are
used in the design and implementation.

% use Git as VCS (and host on GitHub for visibility)
The first of these is to keep the project history in version
control and make the project publicly available as soon as
possible. The choice made here is to use the Git version control
system with the GitHub hosting service (\url{https://github.com/})
since it has been adopted by many other similarly scoped
science projects including Vaa3D, OpenCV, and InsightToolkit; this
gives it easy visibility via search engines. This is to address
the open-science portion of the scientific deliverables as it
allows for a workflow that allows work-in-progress changes to
reside alongside the stable codebase so that even work that is not
yet complete is available as soon as possible.

% choose C for implementation over C++ (ABI stability)
The second principle is to choose an implementation language that
makes integration easy (i.e., the second engineering objective).
The choices for native languages that are widely available for
this purpose are C and C++. Due to the way C++ implements
naming conventions through \emph{name mangling}, this can
complicate the integration process and make the library
maintenance more challenging due to changes in the \acrshort{ABI}.
To mitigate this, one common approach to implement a C wrapper
\acrshort{API}/\acrshort{ABI} around an existing C++ \acrshort{API}
in what is known as an hour-glass interface~\autocite{CppCon:Hourglass:2014}.
This provides a stabilised \acrshort{ABI} which means that if
libraries are updated independent of the \gls{orionc} code, then
the \gls{orionc} code will not have to be recompiled. However this can
complicate development by having to maintain two layers, so to
keep the development simplified, the main implementation language
is in C.

% automated builds using GNU Make
As with all software, the \gls{orionc} software has a series of
steps required to prepare the software for building and
installing and since \gls{orionc} is native code, these steps can
be complex because it needs to run on multiple platforms. As such,
it is expedient to create an automated build system that outlines
the steps needed to build \gls{orionc} so that the process of
creating the final binaries is replicable by anyone that obtains
\gls{orionc} and reduces the need for reading manual instructions.
This automated build system should also be able to run tests to
ensure that the software works as expected. The \gls{orionc}
project uses GNU Make since it is a portable build tool that runs
on many systems. Overall, this specific principle improves
reproducibility.

% do not optimise --- profile
Another principle that is used to guide the development is to
avoid premature optimisation; that is, do not attempt to make the
code more efficient before it is necessary. Instead of guessing
which parts of the code are slow, use a profiler to measure the
bottlenecks in the code. It is also not advisable to focus on
optimisation at the stage of rewriting the software.

% how to approach the rewrite --- as a piecewise conversion
% followed by refactoring
This rewrite should be approached in an incremental manner by
using test-driven development. For example, instead of trying to convert many
modules of \gls{orionmat} at once, each is converted one at a
time after writing tests for that specific component to ensure
that it works independently. This also means that adding new
external dependencies is done at the last possible moment. If a
module of \gls{orionc} requires an \acrshort{FFT} function,
the function should be created first as an empty stub function
that is used to understand the minimum number of parameters needed
to implement the FFT functionality. Then when the external dependency
is incorporated, the call to the external library can be placed in
the stub. This helps avoid creating coupling with the external
library so that different approaches can easily be tried by only
having to change the code at a single spot.

\section{Challenges and risks}

While the code for the algorithm already exists, starting with a line-by-line
translation of the MATLAB code has some limitations outlined as follows.
\begin{description}
\item[Toolbox\label{desc:matlab:toolbox}] The code is written to use MATLAB's extensive 
	specialised toolboxes for image processing and
	statistics which means that equivalents must be
	incorporated into the new codebase.
\item[Memory management\label{desc:matlab:mem}] Since MATLAB is a dynamic array language with
	automatic memory management, it is simple to create
	multidimensional array and extend it without having to
	keep track of the variable's size or the variable
	lifetime. Since C uses manual memory management, it is
	necessary to manually allocate and release memory to avoid
	memory leaks.
\item[Data layout differences]
	MATLAB uses column-major and 1-based indexing, while C/C++
	both used row-major and 0-based indexing. Some of the code
	will be written with the assumption that all indices start
	at 1 and this may not be documented everywhere. This is
	discussed in more detail in Section~\ref{subsec:impl:ds}.
\item[Caching\label{desc:matlab:cache}] The \gls{orionmat} code makes frequent use of the file system
	to cache calculations between runs. The purpose of this is
	to speed up experiments so that when an experiment is
	rerun, any images that have been processed in an earlier
	stage (i.e., segmentation) do not need to be reprocessed
	in later stages (i.e., centreline extraction). Code
	written in this form imposes an algorithm structure
	that is no longer strictly imperative --- the code is now
	interspersed with checks to see if the data already exists
	and instead of passing the data between functions using
	multidimensional arrays as parameters, the parameters to
	the functions are filenames.
\item[Subvolume\label{desc:matlab:subvol}] The MATLAB code breaks up the input data into
	subvolumes. This allows the computation to run a small
	region of the data which allows for processing data that
	may be too large to fit entirely memory. Furthermore, when
	used in conjunction with the aforementioned caching, the
	steps used for each processing stage can be more granular
	which means that if any processing is incomplete (e.g.,
	because the computer runs out of memory or disk space),
	the data is not entirely lost. However, this complicates
	the algorithm because any calculation involving
	coordinates in a volume must map indices in subvolumes to
	indices in the corresponding supervolume.
\end{description}

The \nameref{desc:matlab:cache} and \nameref{desc:matlab:subvol}
issues both indicate issues that can be described as cross-cutting
concerns. Cross-cutting concerns are parts of the program design
that do not reside within only a subset of the system and cause
dependencies between subsystems. These often manifest when an
action must be taken in every module of a system. A classic
example of this is logging --- logging must be done in each
module, but this requires that logging metadata must be persisted
so that each module can use it. This persistence adds an input to
each module that does not strictly relate to the function of
that module. In the same way, caching and handling of subvolumes
both require that each step read all subvolumes of the previous
step and write all the subvolumes that will be used in the next
step. This filename-based coupling makes it difficult to treat
each step as a self-contained module. By removing these concerns
altogether in the new design, the \gls{orionc} system will be more
extensible and modular.

\section{Roads not taken}

There were two possible ways to avoid having to do a rewrite that
were possible solutions to some of the objectives listed above.
These were not chosen because they would have not met the primary
scientific deliverable (open-science) nor the fourth objective
(reproducibility). Both of these approaches allow for calling
MATLAB from C code and thus allow for processing with
\gls{orionmat}. These approaches are as follows:
\begin{description}
\item[Using the MATLAB Engine API] This allows for controlling a
	MATLAB instance using inter-process communication which
	means each run requires starting a MATLAB process with a
	valid MATLAB license. This means that \gls{orionmat}
	can not be run multiple times as each run will use an
	additional MATLAB licenese. This precludes using
	\gls{orionmat} on a cluster as each additional process
	will fail when the number of licenses has run out.
	Furthermore, the startup time for each MATLAB process is
	significant enough to slow down each volume processed.
	This does not meet the reproducibility criteria of the
	fourth objective as it requires the end-user to have a
	license that may be difficult to obtain and furthermore
	can tie the software to a specific version of that
	software.
\item[Using the MATLAB Compiler Runtime] This approach allows for
	distributing MATLAB code to people that do not have
	MATLAB by using the MATLAB Compiler Runtime along with an
	encrypted archive of the \gls{orionmat} workspace. Unlike
	the MATLAB Engine API, this can be used in parallel.
	However, the encrypted archive is tied to a single
	operating system (e.g., Windows, GNU/Linux) and computer
	architecture (e.g., IA32 or IA64). This makes
	reproducibility difficult since the compilation can only
	be done on the same kind of computer and version of MATLAB
	as the corresponding version of the MATLAB Compiler
	Runtime. This also violates the primary
	scientific deliverable (open-science) since the deployed
	code is encrypted and others can not see how the
	algorithms are implemented.
\end{description}
