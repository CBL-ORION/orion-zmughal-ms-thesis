\begin{savequote}[0.55\linewidth]
	\begin{fancyquote}
		Measure twice and cut once.
	\end{fancyquote}
	\qauthor{Carpentry rule of thumb}

	\begin{fancyquote}
		But cut\hspace{1em}ting is more fun than m\hspace{0.5em}\raisebox{-0.1em}{eas}\hspace{0.5em}\raisebox{-0.3em}{uri}\hspace{0.5em}\raisebox{-0.5em}{ng!}
	\end{fancyquote}
	\qauthor{Anonymous}
\end{savequote}

\chapter{Planning and Analysis}\label{ch:analysis}
% 2. Planning and Analysis
%    [ Analysis of project requirements. How is the older codebase
%      structured. How is refactoring accomplished. ]

Before writing a single line of code, it is a good practice to understand the
scope of the problem. Gathering the deliverables and requirements of the
project is necessary not only for understanding how long the project will take,
but also the order in which to implement each component. Establishing this
order proves very useful for later in the testing phase of the project
(\cref{ch:testing}).

\section{Design principles}
% Define technical principles that relate to project objectives

In order to meet the objectives listed in \cref{sec:objectives},
certain principles need to be agreed upon before the design phase
can begin. These principles are meant to direct how resources are
used in the design and implementation.

% use Git as VCS (and host on GitHub for visibility)
The first of these is to keep the project history in version
control and make the project publicly available as soon as
possible. The choice made here is to use the Git version control
system with the GitHub hosting service (\url{https://github.com/})
since it has been adopted by many other similarly scoped
science projects including Vaa3D, OpenCV, and InsightToolkit; this
gives it easy visibility via search engines. This is to address
the open-science portion of the scientific outcome as it
allows for a workflow that allows work-in-progress changes to
reside alongside the stable codebase so that even work that is not
yet complete is available as soon as possible.

% choose C for implementation over C++ (ABI stability)
The second principle is to choose an implementation language that
makes integration easy (i.e., the second engineering objective).
The choices for native languages that are widely available for
this purpose are C and C++. Due to the way C++ implements
naming conventions through \emph{name mangling}, this can
complicate the integration process and make the library
maintenance more challenging due to changes in the \acrshort{ABI}.
To mitigate this, one common approach to implement a C wrapper
\acrshort{API}/\acrshort{ABI} around an existing C++ \acrshort{API}
in what is known as an hour-glass interface~\autocite{CppCon:Hourglass:2014}.
This provides a stabilised \acrshort{ABI} which means that if
libraries are updated independent of the \gls{orionc} code, then
the \gls{orionc} code will not have to be recompiled. However this can
complicate development by having to maintain two layers, so to
keep the development simplified, the main implementation language
is in C.

% automated builds using GNU Make
As with all software, the \gls{orionc} software has a series of
steps required to prepare the software for building and
installing and since \gls{orionc} is native code, these steps can
be complex because it needs to run on multiple platforms. As such,
it is expedient to create an automated build system that outlines
the steps needed to build \gls{orionc} so that the process of
creating the final binaries is replicable by anyone that obtains
\gls{orionc} and reduces the need for reading manual instructions.
This automated build system should also be able to run tests to
ensure that the software works as expected. The \gls{orionc}
project uses GNU Make since it is a portable build tool that runs
on many systems. Overall, this specific principle improves
reproducibility.

% do not optimise --- profile
Another principle that is used to guide the development is to
avoid premature optimisation; that is, do not attempt to make the
code more efficient before it is necessary. Instead of guessing
which parts of the code are slow, use a profiler to measure the
bottlenecks in the code. It is also not advisable to focus on
optimisation at the stage of rewriting the software.

% how to approach the rewrite --- as a piecewise conversion
% followed by refactoring
This rewrite should be approached in an incremental manner by
using test-driven development. For example, instead of trying to convert many
modules of \gls{orionmat} at once, each is converted one at a
time after writing tests for that specific component to ensure
that it works independently. This also means that adding new
external dependencies is done at the last possible moment. If a
module of \gls{orionc} requires an \acrshort{FFT} function,
the function should be created first as an empty stub function
that is used to understand the minimum number of parameters needed
to implement the FFT functionality. Then when the external dependency
is incorporated, the call to the external library can be placed in
the stub. This helps avoid creating coupling with the external
library so that different approaches can easily be tried by only
having to change the code at a single spot.

\section{Challenges and risks}

While the code for the algorithm already exists, starting with a line-by-line
translation of the MATLAB code has some limitations outlined as follows.
\begin{description}[font=\textpluscolon]
\item[Toolbox\label{desc:matlab:toolbox}] The code is written to use MATLAB's extensive 
	specialised toolboxes for image processing and
	statistics which means that equivalents must be
	incorporated into the new codebase.
\item[Memory management\label{desc:matlab:mem}] Since MATLAB is a dynamic array language with
	automatic memory management, it is simple to create
	multidimensional array and extend it without having to
	keep track of the variable's size or the variable
	lifetime. Since C uses manual memory management, it is
	necessary to manually allocate and release memory to avoid
	memory leaks.
\item[Data layout differences]
	MATLAB uses column-major and 1-based indexing, while C/C++
	both used row-major and 0-based indexing. Some of the code
	will be written with the assumption that all indices start
	at 1 and this may not be documented everywhere. This is
	discussed in more detail in \cref{subsec:impl:ds}.
\item[Caching\label{desc:matlab:cache}] The \gls{orionmat} code makes frequent use of the file system
	to cache calculations between runs. The purpose of this is
	to speed up experiments so that when an experiment is
	rerun, any images that have been processed in an earlier
	stage (i.e., segmentation) do not need to be reprocessed
	in later stages (i.e., centreline extraction). Code
	written in this form imposes an algorithm structure
	that is no longer strictly imperative --- the code is now
	interspersed with checks to see if the data already exists
	and instead of passing the data between functions using
	multidimensional arrays as parameters, the parameters to
	the functions are filenames.
\item[Subvolume\label{desc:matlab:subvol}] The MATLAB code breaks up the input data into
	subvolumes. This allows the computation to run a small
	region of the data which allows for processing data that
	may be too large to fit entirely memory. Furthermore, when
	used in conjunction with the aforementioned caching, the
	steps used for each processing stage can be more granular
	which means that if any processing is incomplete (e.g.,
	because the computer runs out of memory or disk space),
	the data is not entirely lost. However, this complicates
	the algorithm because any calculation involving
	coordinates in a volume must map indices in subvolumes to
	indices in the corresponding supervolume.
\end{description}

The \nameref{desc:matlab:cache} and \nameref{desc:matlab:subvol}
issues can both be described as design decisions that result in cross-cutting
concerns. Cross-cutting concerns are parts of the program design
that do not reside within only a subset of the system and cause
dependencies between subsystems. These often manifest when an
action must be taken in every module of a system. A classic
example of this is logging --- logging must be done in each
module, but this requires that logging metadata must be persisted
so that each module can use it. This persistence adds an input to
each module that does not strictly relate to the function of
that module. In the same way, caching and handling of subvolumes
both require that each step read all subvolumes of the previous
step and write all the subvolumes that will be used in the next
step. This filename-based coupling makes it difficult to treat
each step as a self-contained module. By removing these concerns
altogether in the new design, the \gls{orionc} system will be more
extensible and modular.

\section{Roads not taken}

There were two possible ways to avoid having to do a rewrite that
could have fulfilled some of the objectives listed above.
These were not chosen because they would have not met the primary
scientific outcome (open-science) nor the fourth objective
(reproducibility). Both of these approaches allow for calling
MATLAB from C code and thus allow for processing with
\gls{orionmat}.

{
	% Using the MATLAB Engine API
	The first of these approaches is to use the standard
	\emph{MATLAB Engine API} that comes with MATLAB. This allows for controlling a
	MATLAB instance using inter-process communication which
	means each run requires starting a MATLAB process with a
	valid MATLAB license. This means that \gls{orionmat}
	can not be run multiple times as each run will use an
	additional MATLAB license. This precludes using
	\gls{orionmat} on a cluster as each additional process
	will fail when the number of licenses has run out.
	Furthermore, the startup time for each MATLAB process is
	significant enough to slow down each volume processed.
	This does not meet the reproducibility criteria of the
	fourth objective as it requires the end-user to have a
	license that may be difficult to obtain and furthermore
	can tie the software to a specific version of the MATLAB
	software.
}

{
	% Using the MATLAB Compiler Runtime
	The second approach is to use the MATLAB Compiler tool
	to generate a dynamic library (e.g., \computertext{liborion3mat.so} on GNU/Linux and
	\computertext{liborion3mat.dll} on Windows)
	from the \gls{orionmat} code that can be linked to C/C++ code.
	This allows for
	distributing MATLAB code to people that do not have
	MATLAB by using the MATLAB Compiler Runtime along with an
	encrypted archive of the \gls{orionmat} workspace. Unlike
	the MATLAB Engine API, this can be used in parallel.
	However, the encrypted archive is tied to a single
	operating system (e.g., Windows, GNU/Linux) and computer
	architecture (e.g., i386 or x86-64). This makes
	reproducibility difficult since the dynamic library can
	only be generated on the same kind of computer and version
	of MATLAB as the corresponding version of the MATLAB
	Compiler Runtime.

	A preliminary prototype of the MATLAB Compiler approach
	for interfacing with MATLAB was attempted in the Analysis
	phase, but rejected as it made distribution difficult and
	added a large binary dependency that would need to
	be maintained in addition to the \gls{orionmat} code. This
	approach could work for a research project where the
	ability for others to run the code on different data sets
	is sufficient. This can be accomplished by creating a
	lightweight virtual machine that comes pre-installed with
	the library and MATLAB Compiler Runtime. Those without
	access to MATLAB will still be able to run the algorithm
	as is, but will not able to adapt it by modifying the
	code. However, we reject this approach in the context of
	\gls{orion3} as it would violate the primary scientific
	outcome (open-science) since encrypted code prevents
	others from seeing how the algorithms for \gls{orionmat}
	and MATLAB are implemented.
}

Although we reject the above approaches, there is a benefit to
using MATLAB. Writing native code rather than MATLAB code can
make maintenance and reproducibility more difficult if the
development does not aim for those goals early on~\autocite{Donoho2009,Collberg2015}.
Many considerations go into creating portable software and many of
these same considerations are also necessary for reproducible
computational science (e.g., file system handling, floating point accuracy,
compiler differences, and dynamic libraries)~\autocite{PortableCode:Hook:2005}.
The developers of MATLAB have already done much of the work required
to make MATLAB portable across different operating systems.
Fortunately, the \gls{orionmat} code only needs simple file system
handling support. Other issues such as the aforementioned floating
point accuracy and compiler differences are still unresolved by
MATLAB itself and must be addressed in \gls{orionc}. Further
discussion about these and other issues is \cref{ch:implementation,ch:testing}.
